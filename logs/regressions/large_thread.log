2025-11-26 02:29:07,726 WETEXT INFO found existing fst: /home/admin-grant-jr/github/index-tts/indextts/utils/tagger_cache/zh_tn_tagger.fst
2025-11-26 02:29:07,726 WETEXT INFO                     /home/admin-grant-jr/github/index-tts/indextts/utils/tagger_cache/zh_tn_verbalizer.fst
2025-11-26 02:29:07,726 WETEXT INFO skip building fst for zh_normalizer ...
2025-11-26 02:29:08,236 WETEXT INFO found existing fst: /home/admin-grant-jr/github/index-tts/.venv/lib/python3.10/site-packages/tn/en_tn_tagger.fst
2025-11-26 02:29:08,236 WETEXT INFO                     /home/admin-grant-jr/github/index-tts/.venv/lib/python3.10/site-packages/tn/en_tn_verbalizer.fst
2025-11-26 02:29:08,236 WETEXT INFO skip building fst for en_normalizer ...
Using thread backend with worker-count=2 on device=cuda:0
>> GPT weights restored from: checkpoints/gpt.pth
>> semantic_codec weights restored from: ./checkpoints/hf_cache/models--amphion--MaskGCT/snapshots/265c6cef07625665d0c28d2faafb1415562379dc/semantic_codec/model.safetensors
cfm loaded
length_regulator loaded
gpt_layer loaded
>> s2mel weights restored from: checkpoints/s2mel.pth
>> campplus_model weights restored from: ./checkpoints/hf_cache/models--funasr--campplus/snapshots/fb71fe990cbf6031ae6987a2d76fe64f94377b7e/campplus_cn_common.bin
Loading weights from nvidia/bigvgan_v2_22khz_80band_256x
Removing weight norm...
>> bigvgan weights restored from: nvidia/bigvgan_v2_22khz_80band_256x
>> TextNormalizer loaded
>> bpe model loaded from: checkpoints/bpe.model
>> starting inference...
Use the specified emotion vector
  0%|          | 0/25 [00:00<?, ?it/s]  4%|▍         | 1/25 [00:00<00:05,  4.57it/s] 16%|█▌        | 4/25 [00:00<00:01, 11.89it/s] 24%|██▍       | 6/25 [00:00<00:01, 12.06it/s] 32%|███▏      | 8/25 [00:00<00:01, 12.13it/s] 40%|████      | 10/25 [00:00<00:01, 12.16it/s] 48%|████▊     | 12/25 [00:01<00:01, 12.18it/s] 56%|█████▌    | 14/25 [00:01<00:00, 12.19it/s] 64%|██████▍   | 16/25 [00:01<00:00, 12.17it/s] 72%|███████▏  | 18/25 [00:01<00:00, 12.16it/s] 80%|████████  | 20/25 [00:01<00:00, 12.16it/s] 88%|████████▊ | 22/25 [00:01<00:00, 12.17it/s] 96%|█████████▌| 24/25 [00:02<00:00, 12.18it/s]100%|██████████| 25/25 [00:02<00:00, 11.92it/s]
torch.Size([1, 77824])
>> gpt_gen_time: 8.95 seconds
>> gpt_forward_time: 0.04 seconds
>> s2mel_time: 2.12 seconds
>> bigvgan_time: 0.48 seconds
>> Total inference time: 14.66 seconds
>> Generated audio length: 3.53 seconds
>> RTF: 4.1526
>> starting inference...
Use the specified emotion vector
  0%|          | 0/25 [00:00<?, ?it/s]  4%|▍         | 1/25 [00:00<00:04,  5.40it/s] 12%|█▏        | 3/25 [00:00<00:02,  7.98it/s] 16%|█▌        | 4/25 [00:00<00:03,  6.01it/s] 20%|██        | 5/25 [00:00<00:03,  5.20it/s] 24%|██▍       | 6/25 [00:01<00:03,  4.78it/s] 28%|██▊       | 7/25 [00:01<00:03,  4.53it/s] 32%|███▏      | 8/25 [00:01<00:03,  4.38it/s] 36%|███▌      | 9/25 [00:01<00:03,  4.28it/s] 40%|████      | 10/25 [00:02<00:03,  4.21it/s] 44%|████▍     | 11/25 [00:02<00:03,  4.17it/s] 48%|████▊     | 12/25 [00:02<00:03,  4.14it/s] 52%|█████▏    | 13/25 [00:02<00:02,  4.11it/s] 56%|█████▌    | 14/25 [00:03<00:02,  4.10it/s] 60%|██████    | 15/25 [00:03<00:02,  4.08it/s] 64%|██████▍   | 16/25 [00:03<00:02,  4.07it/s] 68%|██████▊   | 17/25 [00:03<00:01,  4.06it/s] 72%|███████▏  | 18/25 [00:04<00:01,  4.05it/s] 76%|███████▌  | 19/25 [00:04<00:01,  4.05it/s] 80%|████████  | 20/25 [00:04<00:01,  4.05it/s] 84%|████████▍ | 21/25 [00:04<00:00,  4.05it/s] 88%|████████▊ | 22/25 [00:05<00:00,  4.04it/s] 92%|█████████▏| 23/25 [00:05<00:00,  4.04it/s] 96%|█████████▌| 24/25 [00:05<00:00,  4.04it/s]100%|██████████| 25/25 [00:05<00:00,  4.04it/s]100%|██████████| 25/25 [00:05<00:00,  4.30it/s]
torch.Size([1, 125440])
>> gpt_gen_time: 13.62 seconds
>> gpt_forward_time: 0.03 seconds
>> s2mel_time: 5.84 seconds
>> bigvgan_time: 0.81 seconds
>> Total inference time: 20.50 seconds
>> Generated audio length: 5.69 seconds
>> RTF: 3.6033
>> starting inference...
[1] wrote data_stereo/case_001.wav (duration=5.69s, cumulative=5.69s)
Use the specified emotion vector
  0%|          | 0/25 [00:00<?, ?it/s] 12%|█▏        | 3/25 [00:00<00:01, 16.00it/s] 20%|██        | 5/25 [00:00<00:01, 13.70it/s] 28%|██▊       | 7/25 [00:00<00:01, 13.04it/s] 36%|███▌      | 9/25 [00:00<00:01, 12.75it/s] 44%|████▍     | 11/25 [00:00<00:01, 12.56it/s] 52%|█████▏    | 13/25 [00:01<00:00, 12.45it/s] 60%|██████    | 15/25 [00:01<00:00, 12.38it/s] 68%|██████▊   | 17/25 [00:01<00:00, 12.29it/s] 76%|███████▌  | 19/25 [00:01<00:00, 12.22it/s] 84%|████████▍ | 21/25 [00:01<00:00, 12.22it/s] 92%|█████████▏| 23/25 [00:01<00:00, 12.21it/s]100%|██████████| 25/25 [00:01<00:00, 12.19it/s]100%|██████████| 25/25 [00:01<00:00, 12.52it/s]
torch.Size([1, 77824])
>> gpt_gen_time: 11.79 seconds
>> gpt_forward_time: 0.04 seconds
>> s2mel_time: 2.01 seconds
>> bigvgan_time: 0.34 seconds
>> Total inference time: 14.31 seconds
>> Generated audio length: 3.53 seconds
>> RTF: 4.0531
>> starting inference...
Use the specified emotion vector
  0%|          | 0/25 [00:00<?, ?it/s]  4%|▍         | 1/25 [00:00<00:06,  3.58it/s] 12%|█▏        | 3/25 [00:00<00:03,  6.83it/s] 16%|█▌        | 4/25 [00:00<00:03,  5.42it/s] 20%|██        | 5/25 [00:00<00:04,  4.91it/s] 24%|██▍       | 6/25 [00:01<00:04,  4.57it/s] 28%|██▊       | 7/25 [00:01<00:04,  4.36it/s] 32%|███▏      | 8/25 [00:01<00:04,  4.23it/s] 36%|███▌      | 9/25 [00:01<00:03,  4.14it/s] 40%|████      | 10/25 [00:02<00:03,  4.08it/s] 44%|████▍     | 11/25 [00:02<00:03,  4.04it/s] 48%|████▊     | 12/25 [00:02<00:03,  4.02it/s] 52%|█████▏    | 13/25 [00:02<00:03,  3.99it/s] 56%|█████▌    | 14/25 [00:03<00:02,  3.98it/s] 60%|██████    | 15/25 [00:03<00:02,  3.96it/s] 64%|██████▍   | 16/25 [00:03<00:02,  3.95it/s] 68%|██████▊   | 17/25 [00:04<00:02,  3.94it/s] 72%|███████▏  | 18/25 [00:04<00:01,  3.94it/s] 76%|███████▌  | 19/25 [00:04<00:01,  3.93it/s] 80%|████████  | 20/25 [00:04<00:01,  3.92it/s] 84%|████████▍ | 21/25 [00:05<00:01,  3.92it/s] 88%|████████▊ | 22/25 [00:05<00:00,  3.92it/s] 92%|█████████▏| 23/25 [00:05<00:00,  3.91it/s] 96%|█████████▌| 24/25 [00:05<00:00,  3.91it/s]100%|██████████| 25/25 [00:06<00:00,  3.91it/s]100%|██████████| 25/25 [00:06<00:00,  4.13it/s]
torch.Size([1, 146176])
>> gpt_gen_time: 15.76 seconds
>> gpt_forward_time: 0.05 seconds
>> s2mel_time: 6.08 seconds
>> bigvgan_time: 0.89 seconds
>> Total inference time: 23.01 seconds
>> Generated audio length: 6.63 seconds
>> RTF: 3.4712
>> starting inference...
[2] wrote data_stereo/case_002.wav (duration=6.63s, cumulative=12.32s)
Use the specified emotion vector
  0%|          | 0/25 [00:00<?, ?it/s] 12%|█▏        | 3/25 [00:00<00:01, 16.24it/s] 20%|██        | 5/25 [00:00<00:01, 14.09it/s] 28%|██▊       | 7/25 [00:00<00:01, 13.27it/s] 36%|███▌      | 9/25 [00:00<00:01, 12.85it/s] 44%|████▍     | 11/25 [00:00<00:01, 12.64it/s] 52%|█████▏    | 13/25 [00:01<00:00, 12.49it/s] 60%|██████    | 15/25 [00:01<00:00, 12.39it/s] 68%|██████▊   | 17/25 [00:01<00:00, 12.31it/s] 76%|███████▌  | 19/25 [00:01<00:00, 12.27it/s] 84%|████████▍ | 21/25 [00:01<00:00, 12.24it/s] 92%|█████████▏| 23/25 [00:01<00:00, 12.21it/s]100%|██████████| 25/25 [00:01<00:00, 12.19it/s]100%|██████████| 25/25 [00:01<00:00, 12.58it/s]
torch.Size([1, 77312])
>> gpt_gen_time: 9.60 seconds
>> gpt_forward_time: 0.04 seconds
>> s2mel_time: 2.00 seconds
>> bigvgan_time: 0.33 seconds
>> Total inference time: 12.09 seconds
>> Generated audio length: 3.51 seconds
>> RTF: 3.4471
>> starting inference...
Use the specified emotion vector
  0%|          | 0/25 [00:00<?, ?it/s]  8%|▊         | 2/25 [00:00<00:01, 14.11it/s] 16%|█▌        | 4/25 [00:00<00:03,  6.50it/s] 20%|██        | 5/25 [00:00<00:03,  5.85it/s] 24%|██▍       | 6/25 [00:00<00:03,  5.45it/s] 28%|██▊       | 7/25 [00:01<00:03,  5.20it/s] 32%|███▏      | 8/25 [00:01<00:03,  5.04it/s] 36%|███▌      | 9/25 [00:01<00:03,  4.93it/s] 40%|████      | 10/25 [00:01<00:03,  4.85it/s] 44%|████▍     | 11/25 [00:02<00:02,  4.80it/s] 48%|████▊     | 12/25 [00:02<00:02,  4.76it/s] 52%|█████▏    | 13/25 [00:02<00:02,  4.73it/s] 56%|█████▌    | 14/25 [00:02<00:02,  4.72it/s] 60%|██████    | 15/25 [00:02<00:02,  4.71it/s] 64%|██████▍   | 16/25 [00:03<00:01,  4.69it/s] 68%|██████▊   | 17/25 [00:03<00:01,  4.68it/s] 72%|███████▏  | 18/25 [00:03<00:01,  4.68it/s] 76%|███████▌  | 19/25 [00:03<00:01,  4.67it/s] 80%|████████  | 20/25 [00:03<00:01,  4.67it/s] 84%|████████▍ | 21/25 [00:04<00:00,  4.67it/s] 88%|████████▊ | 22/25 [00:04<00:00,  4.67it/s] 92%|█████████▏| 23/25 [00:04<00:00,  4.65it/s] 96%|█████████▌| 24/25 [00:04<00:00,  4.65it/s]100%|██████████| 25/25 [00:05<00:00,  4.63it/s]100%|██████████| 25/25 [00:05<00:00,  4.94it/s]
torch.Size([1, 94208])
>> gpt_gen_time: 12.07 seconds
>> gpt_forward_time: 0.04 seconds
>> s2mel_time: 5.08 seconds
>> bigvgan_time: 0.59 seconds
>> Total inference time: 17.95 seconds
>> Generated audio length: 4.27 seconds
>> RTF: 4.2015
>> starting inference...
[3] wrote data_stereo/case_003.wav (duration=4.27s, cumulative=16.59s)
Use the specified emotion vector
  0%|          | 0/25 [00:00<?, ?it/s]  8%|▊         | 2/25 [00:00<00:01, 15.86it/s] 16%|█▌        | 4/25 [00:00<00:01, 11.91it/s] 24%|██▍       | 6/25 [00:00<00:01, 11.68it/s] 32%|███▏      | 8/25 [00:00<00:01, 11.58it/s] 40%|████      | 10/25 [00:00<00:01, 11.51it/s] 48%|████▊     | 12/25 [00:01<00:01, 11.48it/s] 56%|█████▌    | 14/25 [00:01<00:00, 11.28it/s] 64%|██████▍   | 16/25 [00:01<00:00, 11.44it/s] 72%|███████▏  | 18/25 [00:01<00:00, 11.42it/s] 80%|████████  | 20/25 [00:01<00:00, 11.41it/s] 88%|████████▊ | 22/25 [00:01<00:00, 11.39it/s] 96%|█████████▌| 24/25 [00:02<00:00, 11.38it/s]100%|██████████| 25/25 [00:02<00:00, 11.52it/s]
torch.Size([1, 86272])
>> gpt_gen_time: 10.62 seconds
>> gpt_forward_time: 0.05 seconds
>> s2mel_time: 2.18 seconds
>> bigvgan_time: 0.36 seconds
>> Total inference time: 13.35 seconds
>> Generated audio length: 3.91 seconds
>> RTF: 3.4121
>> starting inference...
Use the specified emotion vector
  0%|          | 0/25 [00:00<?, ?it/s]  4%|▍         | 1/25 [00:00<00:07,  3.11it/s] 12%|█▏        | 3/25 [00:00<00:02,  7.94it/s] 20%|██        | 5/25 [00:01<00:04,  4.50it/s] 24%|██▍       | 6/25 [00:01<00:04,  4.05it/s] 28%|██▊       | 7/25 [00:01<00:04,  3.76it/s] 32%|███▏      | 8/25 [00:02<00:04,  3.58it/s] 36%|███▌      | 9/25 [00:02<00:04,  3.45it/s] 40%|████      | 10/25 [00:02<00:04,  3.36it/s] 44%|████▍     | 11/25 [00:02<00:04,  3.30it/s] 48%|████▊     | 12/25 [00:03<00:03,  3.25it/s] 52%|█████▏    | 13/25 [00:03<00:03,  3.22it/s] 56%|█████▌    | 14/25 [00:03<00:03,  3.20it/s] 60%|██████    | 15/25 [00:04<00:03,  3.19it/s] 64%|██████▍   | 16/25 [00:04<00:02,  3.17it/s] 68%|██████▊   | 17/25 [00:04<00:02,  3.16it/s] 72%|███████▏  | 18/25 [00:05<00:02,  3.15it/s] 76%|███████▌  | 19/25 [00:05<00:01,  3.15it/s] 80%|████████  | 20/25 [00:05<00:01,  3.12it/s] 84%|████████▍ | 21/25 [00:06<00:01,  3.15it/s] 88%|████████▊ | 22/25 [00:06<00:00,  3.14it/s] 92%|█████████▏| 23/25 [00:06<00:00,  3.14it/s] 96%|█████████▌| 24/25 [00:07<00:00,  3.13it/s]100%|██████████| 25/25 [00:07<00:00,  3.11it/s]100%|██████████| 25/25 [00:07<00:00,  3.37it/s]
torch.Size([1, 224512])
>> gpt_gen_time: 29.32 seconds
>> gpt_forward_time: 0.03 seconds
>> s2mel_time: 7.46 seconds
>> bigvgan_time: 0.99 seconds
>> Total inference time: 38.15 seconds
>> Generated audio length: 10.18 seconds
>> RTF: 3.7467
>> starting inference...
[4] wrote data_stereo/case_004.wav (duration=10.18s, cumulative=26.77s)
Use the specified emotion vector
  0%|          | 0/25 [00:00<?, ?it/s]  8%|▊         | 2/25 [00:00<00:01, 13.92it/s] 16%|█▌        | 4/25 [00:00<00:01, 13.70it/s] 24%|██▍       | 6/25 [00:00<00:01, 12.94it/s] 32%|███▏      | 8/25 [00:00<00:01, 12.62it/s] 40%|████      | 10/25 [00:00<00:01, 12.43it/s] 48%|████▊     | 12/25 [00:00<00:01, 12.31it/s] 56%|█████▌    | 14/25 [00:01<00:00, 12.21it/s] 64%|██████▍   | 16/25 [00:01<00:00, 12.18it/s] 72%|███████▏  | 18/25 [00:01<00:00, 12.13it/s] 80%|████████  | 20/25 [00:01<00:00, 12.10it/s] 88%|████████▊ | 22/25 [00:01<00:00, 12.08it/s] 96%|█████████▌| 24/25 [00:01<00:00, 12.03it/s]100%|██████████| 25/25 [00:02<00:00, 12.23it/s]
torch.Size([1, 75520])
>> gpt_gen_time: 10.42 seconds
>> gpt_forward_time: 0.06 seconds
>> s2mel_time: 2.06 seconds
>> bigvgan_time: 0.32 seconds
>> Total inference time: 13.00 seconds
>> Generated audio length: 3.42 seconds
>> RTF: 3.7962
>> starting inference...
Use the specified emotion vector
  0%|          | 0/25 [00:00<?, ?it/s]  8%|▊         | 2/25 [00:00<00:01, 15.55it/s] 16%|█▌        | 4/25 [00:00<00:03,  5.80it/s] 20%|██        | 5/25 [00:00<00:03,  5.11it/s] 24%|██▍       | 6/25 [00:01<00:04,  4.72it/s] 28%|██▊       | 7/25 [00:01<00:04,  4.48it/s] 32%|███▏      | 8/25 [00:01<00:03,  4.32it/s] 36%|███▌      | 9/25 [00:01<00:03,  4.21it/s] 40%|████      | 10/25 [00:02<00:03,  4.14it/s] 44%|████▍     | 11/25 [00:02<00:03,  4.09it/s] 48%|████▊     | 12/25 [00:02<00:03,  4.05it/s] 52%|█████▏    | 13/25 [00:02<00:02,  4.03it/s] 56%|█████▌    | 14/25 [00:03<00:02,  4.01it/s] 60%|██████    | 15/25 [00:03<00:02,  4.00it/s] 64%|██████▍   | 16/25 [00:03<00:02,  3.99it/s] 68%|██████▊   | 17/25 [00:03<00:02,  3.98it/s] 72%|███████▏  | 18/25 [00:04<00:01,  3.97it/s] 76%|███████▌  | 19/25 [00:04<00:01,  3.97it/s] 80%|████████  | 20/25 [00:04<00:01,  3.97it/s] 84%|████████▍ | 21/25 [00:04<00:01,  3.96it/s] 88%|████████▊ | 22/25 [00:05<00:00,  3.96it/s] 92%|█████████▏| 23/25 [00:05<00:00,  3.96it/s] 96%|█████████▌| 24/25 [00:05<00:00,  3.96it/s]100%|██████████| 25/25 [00:05<00:00,  3.98it/s]100%|██████████| 25/25 [00:05<00:00,  4.23it/s]
torch.Size([1, 132864])
>> gpt_gen_time: 15.42 seconds
>> gpt_forward_time: 0.05 seconds
>> s2mel_time: 5.93 seconds
>> bigvgan_time: 0.85 seconds
>> Total inference time: 22.46 seconds
>> Generated audio length: 6.03 seconds
>> RTF: 3.7282
>> starting inference...
[5] wrote data_stereo/case_005.wav (duration=6.03s, cumulative=32.80s)
Use the specified emotion vector
  0%|          | 0/25 [00:00<?, ?it/s] 12%|█▏        | 3/25 [00:00<00:01, 16.79it/s] 20%|██        | 5/25 [00:00<00:01, 14.11it/s] 28%|██▊       | 7/25 [00:00<00:01, 13.07it/s] 36%|███▌      | 9/25 [00:00<00:01, 12.64it/s] 44%|████▍     | 11/25 [00:00<00:01, 12.39it/s] 52%|█████▏    | 13/25 [00:01<00:00, 12.25it/s] 60%|██████    | 15/25 [00:01<00:00, 12.13it/s] 68%|██████▊   | 17/25 [00:01<00:00, 12.06it/s] 76%|███████▌  | 19/25 [00:01<00:00, 12.01it/s] 84%|████████▍ | 21/25 [00:01<00:00, 11.70it/s] 92%|█████████▏| 23/25 [00:01<00:00, 12.02it/s]100%|██████████| 25/25 [00:02<00:00, 11.45it/s]100%|██████████| 25/25 [00:02<00:00, 12.19it/s]
torch.Size([1, 78592])
>> gpt_gen_time: 12.00 seconds
>> gpt_forward_time: 0.04 seconds
>> s2mel_time: 2.06 seconds
>> bigvgan_time: 0.31 seconds
>> Total inference time: 14.55 seconds
>> Generated audio length: 3.56 seconds
>> RTF: 4.0813
>> starting inference...
Use the specified emotion vector
  0%|          | 0/25 [00:00<?, ?it/s]  8%|▊         | 2/25 [00:00<00:01, 14.29it/s] 16%|█▌        | 4/25 [00:00<00:03,  6.32it/s] 20%|██        | 5/25 [00:00<00:03,  5.66it/s] 24%|██▍       | 6/25 [00:01<00:03,  5.28it/s] 28%|██▊       | 7/25 [00:01<00:03,  5.04it/s] 32%|███▏      | 8/25 [00:01<00:03,  4.87it/s] 36%|███▌      | 9/25 [00:01<00:03,  4.77it/s] 40%|████      | 10/25 [00:01<00:03,  4.69it/s] 44%|████▍     | 11/25 [00:02<00:03,  4.65it/s] 48%|████▊     | 12/25 [00:02<00:02,  4.61it/s] 52%|█████▏    | 13/25 [00:02<00:02,  4.58it/s] 56%|█████▌    | 14/25 [00:02<00:02,  4.56it/s] 60%|██████    | 15/25 [00:03<00:02,  4.55it/s] 64%|██████▍   | 16/25 [00:03<00:01,  4.53it/s] 68%|██████▊   | 17/25 [00:03<00:01,  4.50it/s] 72%|███████▏  | 18/25 [00:03<00:01,  4.51it/s] 76%|███████▌  | 19/25 [00:03<00:01,  4.50it/s] 80%|████████  | 20/25 [00:04<00:01,  4.51it/s] 84%|████████▍ | 21/25 [00:04<00:00,  4.51it/s] 88%|████████▊ | 22/25 [00:04<00:00,  4.51it/s] 92%|█████████▏| 23/25 [00:04<00:00,  4.50it/s] 96%|█████████▌| 24/25 [00:05<00:00,  4.50it/s]100%|██████████| 25/25 [00:05<00:00,  4.51it/s]100%|██████████| 25/25 [00:05<00:00,  4.78it/s]
torch.Size([1, 118272])
>> gpt_gen_time: 14.06 seconds
>> gpt_forward_time: 0.04 seconds
>> s2mel_time: 5.25 seconds
>> bigvgan_time: 0.74 seconds
>> Total inference time: 20.30 seconds
>> Generated audio length: 5.36 seconds
>> RTF: 3.7838
>> starting inference...
[6] wrote data_stereo/case_006.wav (duration=5.36s, cumulative=38.16s)
Use the specified emotion vector
  0%|          | 0/25 [00:00<?, ?it/s]  8%|▊         | 2/25 [00:00<00:01, 13.25it/s] 16%|█▌        | 4/25 [00:00<00:03,  6.51it/s] 20%|██        | 5/25 [00:00<00:03,  5.88it/s] 24%|██▍       | 6/25 [00:00<00:03,  5.50it/s] 28%|██▊       | 7/25 [00:01<00:03,  5.25it/s] 32%|███▏      | 8/25 [00:01<00:03,  5.09it/s] 36%|███▌      | 9/25 [00:01<00:03,  4.98it/s] 40%|████      | 10/25 [00:01<00:03,  4.90it/s] 44%|████▍     | 11/25 [00:02<00:02,  4.80it/s] 48%|████▊     | 12/25 [00:02<00:02,  4.79it/s] 52%|█████▏    | 13/25 [00:02<00:02,  4.77it/s] 56%|█████▌    | 14/25 [00:02<00:02,  4.76it/s] 60%|██████    | 15/25 [00:02<00:02,  4.75it/s] 64%|██████▍   | 16/25 [00:03<00:01,  4.74it/s] 68%|██████▊   | 17/25 [00:03<00:01,  4.74it/s] 72%|███████▏  | 18/25 [00:03<00:01,  4.73it/s] 76%|███████▌  | 19/25 [00:03<00:01,  4.73it/s] 80%|████████  | 20/25 [00:03<00:01,  4.71it/s] 84%|████████▍ | 21/25 [00:04<00:00,  4.72it/s] 88%|████████▊ | 22/25 [00:04<00:00,  4.73it/s] 92%|█████████▏| 23/25 [00:04<00:00,  4.72it/s]100%|██████████| 25/25 [00:04<00:00,  5.93it/s]
torch.Size([1, 88320])
>> gpt_gen_time: 10.72 seconds
>> gpt_forward_time: 0.04 seconds
>> s2mel_time: 5.03 seconds
>> bigvgan_time: 0.58 seconds
>> Total inference time: 16.53 seconds
>> Generated audio length: 4.01 seconds
>> RTF: 4.1267
>> starting inference...
Use the specified emotion vector
  0%|          | 0/25 [00:00<?, ?it/s]  8%|▊         | 2/25 [00:00<00:01, 12.49it/s] 16%|█▌        | 4/25 [00:00<00:03,  5.93it/s] 20%|██        | 5/25 [00:00<00:03,  5.20it/s] 24%|██▍       | 6/25 [00:01<00:03,  4.79it/s] 28%|██▊       | 7/25 [00:01<00:03,  4.54it/s] 32%|███▏      | 8/25 [00:01<00:03,  4.37it/s] 36%|███▌      | 9/25 [00:01<00:03,  4.27it/s] 40%|████      | 10/25 [00:02<00:03,  4.19it/s] 44%|████▍     | 11/25 [00:02<00:03,  4.14it/s] 48%|████▊     | 12/25 [00:02<00:03,  4.10it/s] 52%|█████▏    | 13/25 [00:02<00:02,  4.08it/s] 56%|█████▌    | 14/25 [00:03<00:02,  4.06it/s] 60%|██████    | 15/25 [00:03<00:02,  4.05it/s] 64%|██████▍   | 16/25 [00:03<00:02,  4.03it/s] 68%|██████▊   | 17/25 [00:03<00:01,  4.03it/s] 72%|███████▏  | 18/25 [00:04<00:01,  4.02it/s] 76%|███████▌  | 19/25 [00:04<00:01,  4.02it/s] 80%|████████  | 20/25 [00:04<00:01,  4.01it/s] 84%|████████▍ | 21/25 [00:04<00:00,  4.01it/s] 88%|████████▊ | 22/25 [00:05<00:00,  4.00it/s] 92%|█████████▏| 23/25 [00:05<00:00,  4.00it/s] 96%|█████████▌| 24/25 [00:05<00:00,  4.00it/s]100%|██████████| 25/25 [00:05<00:00,  4.00it/s]100%|██████████| 25/25 [00:05<00:00,  4.27it/s]
torch.Size([1, 122368])
>> gpt_gen_time: 14.20 seconds
>> gpt_forward_time: 0.04 seconds
>> s2mel_time: 5.87 seconds
>> bigvgan_time: 0.80 seconds
>> Total inference time: 21.12 seconds
>> Generated audio length: 5.55 seconds
>> RTF: 3.8051
>> starting inference...
[7] wrote data_stereo/case_007.wav (duration=5.55s, cumulative=43.71s)
Use the specified emotion vector
  0%|          | 0/25 [00:00<?, ?it/s]  8%|▊         | 2/25 [00:00<00:01, 17.06it/s] 16%|█▌        | 4/25 [00:00<00:03,  5.76it/s] 20%|██        | 5/25 [00:00<00:03,  5.06it/s] 24%|██▍       | 6/25 [00:01<00:04,  4.65it/s] 28%|██▊       | 7/25 [00:01<00:04,  4.40it/s] 32%|███▏      | 8/25 [00:01<00:04,  4.23it/s] 36%|███▌      | 9/25 [00:01<00:03,  4.14it/s] 40%|████      | 10/25 [00:02<00:03,  4.07it/s] 44%|████▍     | 11/25 [00:02<00:03,  4.01it/s] 48%|████▊     | 12/25 [00:02<00:03,  3.98it/s] 52%|█████▏    | 13/25 [00:02<00:03,  3.95it/s] 56%|█████▌    | 14/25 [00:03<00:02,  3.93it/s] 60%|██████    | 15/25 [00:03<00:02,  3.92it/s] 64%|██████▍   | 16/25 [00:03<00:02,  3.91it/s] 68%|██████▊   | 17/25 [00:03<00:02,  3.90it/s] 72%|███████▏  | 18/25 [00:04<00:01,  3.90it/s] 76%|███████▌  | 19/25 [00:04<00:01,  3.89it/s] 80%|████████  | 20/25 [00:04<00:01,  3.89it/s] 84%|████████▍ | 21/25 [00:04<00:01,  3.89it/s] 88%|████████▊ | 22/25 [00:05<00:00,  3.89it/s] 92%|█████████▏| 23/25 [00:05<00:00,  3.88it/s] 96%|█████████▌| 24/25 [00:05<00:00,  3.88it/s]100%|██████████| 25/25 [00:06<00:00,  3.88it/s]100%|██████████| 25/25 [00:06<00:00,  4.15it/s]
torch.Size([1, 150784])
>> gpt_gen_time: 16.99 seconds
>> gpt_forward_time: 0.05 seconds
>> s2mel_time: 6.04 seconds
>> bigvgan_time: 0.91 seconds
>> Total inference time: 24.22 seconds
>> Generated audio length: 6.84 seconds
>> RTF: 3.5422
>> starting inference...
Use the specified emotion vector
  0%|          | 0/25 [00:00<?, ?it/s]  8%|▊         | 2/25 [00:00<00:01, 13.86it/s] 16%|█▌        | 4/25 [00:00<00:03,  6.50it/s] 20%|██        | 5/25 [00:00<00:03,  5.84it/s] 24%|██▍       | 6/25 [00:00<00:03,  5.45it/s] 28%|██▊       | 7/25 [00:01<00:03,  5.20it/s] 32%|███▏      | 8/25 [00:01<00:03,  5.03it/s] 36%|███▌      | 9/25 [00:01<00:03,  4.92it/s] 40%|████      | 10/25 [00:01<00:03,  4.85it/s] 44%|████▍     | 11/25 [00:02<00:02,  4.80it/s] 48%|████▊     | 12/25 [00:02<00:02,  4.76it/s] 52%|█████▏    | 13/25 [00:02<00:02,  4.73it/s] 56%|█████▌    | 14/25 [00:02<00:02,  4.71it/s] 60%|██████    | 15/25 [00:02<00:02,  4.70it/s] 64%|██████▍   | 16/25 [00:03<00:01,  4.69it/s] 68%|██████▊   | 17/25 [00:03<00:01,  4.68it/s] 72%|███████▏  | 18/25 [00:03<00:01,  4.68it/s] 76%|███████▌  | 19/25 [00:03<00:01,  4.67it/s] 80%|████████  | 20/25 [00:03<00:01,  4.66it/s] 84%|████████▍ | 21/25 [00:04<00:00,  4.65it/s] 88%|████████▊ | 22/25 [00:04<00:00,  4.65it/s] 92%|█████████▏| 23/25 [00:04<00:00,  4.65it/s] 96%|█████████▌| 24/25 [00:04<00:00,  4.65it/s]100%|██████████| 25/25 [00:05<00:00,  4.66it/s]100%|██████████| 25/25 [00:05<00:00,  4.94it/s]
torch.Size([1, 93184])
>> gpt_gen_time: 10.95 seconds
>> gpt_forward_time: 0.04 seconds
>> s2mel_time: 5.08 seconds
>> bigvgan_time: 0.59 seconds
>> Total inference time: 16.81 seconds
>> Generated audio length: 4.23 seconds
>> RTF: 3.9784
[8] wrote data_stereo/case_008.wav (duration=6.84s, cumulative=50.55s)
[threads] Parallel pipeline complete in 303.03s — samples: 8, total duration: 50.55s

Done. JSONL index written to: /tmp/moshi_regress_large_threaded/moshi_parity_harness_threaded.jsonl
Summary -> samples: 8, total duration: 50.55s, avg: 6.32s
You can now run (from moshi-finetune repo):
  python annotate.py /tmp/moshi_regress_large_threaded/moshi_parity_harness_threaded.jsonl
