2025-11-26 02:23:18,219 WETEXT INFO found existing fst: /home/admin-grant-jr/github/index-tts/indextts/utils/tagger_cache/zh_tn_tagger.fst
2025-11-26 02:23:18,219 WETEXT INFO                     /home/admin-grant-jr/github/index-tts/indextts/utils/tagger_cache/zh_tn_verbalizer.fst
2025-11-26 02:23:18,219 WETEXT INFO skip building fst for zh_normalizer ...
2025-11-26 02:23:18,855 WETEXT INFO found existing fst: /home/admin-grant-jr/github/index-tts/.venv/lib/python3.10/site-packages/tn/en_tn_tagger.fst
2025-11-26 02:23:18,855 WETEXT INFO                     /home/admin-grant-jr/github/index-tts/.venv/lib/python3.10/site-packages/tn/en_tn_verbalizer.fst
2025-11-26 02:23:18,855 WETEXT INFO skip building fst for en_normalizer ...
>> GPT weights restored from: checkpoints/gpt.pth
>> semantic_codec weights restored from: ./checkpoints/hf_cache/models--amphion--MaskGCT/snapshots/265c6cef07625665d0c28d2faafb1415562379dc/semantic_codec/model.safetensors
cfm loaded
length_regulator loaded
gpt_layer loaded
>> s2mel weights restored from: checkpoints/s2mel.pth
>> campplus_model weights restored from: ./checkpoints/hf_cache/models--funasr--campplus/snapshots/fb71fe990cbf6031ae6987a2d76fe64f94377b7e/campplus_cn_common.bin
Loading weights from nvidia/bigvgan_v2_22khz_80band_256x
Removing weight norm...
>> bigvgan weights restored from: nvidia/bigvgan_v2_22khz_80band_256x
>> TextNormalizer loaded
>> bpe model loaded from: checkpoints/bpe.model
>> starting inference...
Use the specified emotion vector
  0%|          | 0/25 [00:00<?, ?it/s]  4%|▍         | 1/25 [00:00<00:04,  5.36it/s] 16%|█▌        | 4/25 [00:00<00:01, 12.72it/s] 24%|██▍       | 6/25 [00:00<00:01, 12.89it/s] 32%|███▏      | 8/25 [00:00<00:01, 12.99it/s] 40%|████      | 10/25 [00:00<00:01, 12.94it/s] 48%|████▊     | 12/25 [00:00<00:01, 12.98it/s] 56%|█████▌    | 14/25 [00:01<00:00, 13.01it/s] 64%|██████▍   | 16/25 [00:01<00:00, 13.02it/s] 72%|███████▏  | 18/25 [00:01<00:00, 13.03it/s] 80%|████████  | 20/25 [00:01<00:00, 13.03it/s] 88%|████████▊ | 22/25 [00:01<00:00, 12.98it/s] 96%|█████████▌| 24/25 [00:01<00:00, 11.92it/s]100%|██████████| 25/25 [00:02<00:00, 12.34it/s]
torch.Size([1, 73472])
>> gpt_gen_time: 10.41 seconds
>> gpt_forward_time: 0.04 seconds
>> s2mel_time: 2.06 seconds
>> bigvgan_time: 0.40 seconds
>> Total inference time: 16.32 seconds
>> Generated audio length: 3.33 seconds
>> RTF: 4.8981
>> starting inference...
Use the specified emotion vector
  0%|          | 0/25 [00:00<?, ?it/s]  4%|▍         | 1/25 [00:00<00:04,  5.68it/s] 12%|█▏        | 3/25 [00:00<00:02,  8.88it/s] 16%|█▌        | 4/25 [00:00<00:03,  6.74it/s] 20%|██        | 5/25 [00:00<00:03,  5.85it/s] 24%|██▍       | 6/25 [00:01<00:03,  5.38it/s] 28%|██▊       | 7/25 [00:01<00:03,  5.11it/s] 32%|███▏      | 8/25 [00:01<00:03,  4.94it/s] 36%|███▌      | 9/25 [00:01<00:03,  4.83it/s] 40%|████      | 10/25 [00:01<00:03,  4.76it/s] 44%|████▍     | 11/25 [00:02<00:02,  4.70it/s] 48%|████▊     | 12/25 [00:02<00:02,  4.67it/s] 52%|█████▏    | 13/25 [00:02<00:02,  4.64it/s] 56%|█████▌    | 14/25 [00:02<00:02,  4.63it/s] 60%|██████    | 15/25 [00:02<00:02,  4.62it/s] 64%|██████▍   | 16/25 [00:03<00:01,  4.62it/s] 68%|██████▊   | 17/25 [00:03<00:01,  4.62it/s] 72%|███████▏  | 18/25 [00:03<00:01,  4.63it/s] 76%|███████▌  | 19/25 [00:03<00:01,  4.63it/s] 80%|████████  | 20/25 [00:04<00:01,  4.62it/s] 84%|████████▍ | 21/25 [00:04<00:00,  4.62it/s] 88%|████████▊ | 22/25 [00:04<00:00,  4.62it/s] 92%|█████████▏| 23/25 [00:04<00:00,  4.61it/s] 96%|█████████▌| 24/25 [00:04<00:00,  4.62it/s]100%|██████████| 25/25 [00:05<00:00,  4.61it/s]100%|██████████| 25/25 [00:05<00:00,  4.87it/s]
torch.Size([1, 116480])
>> gpt_gen_time: 15.21 seconds
>> gpt_forward_time: 0.04 seconds
>> s2mel_time: 5.16 seconds
>> bigvgan_time: 0.75 seconds
>> Total inference time: 21.33 seconds
>> Generated audio length: 5.28 seconds
>> RTF: 4.0385
[1] wrote data_stereo/case_001.wav (duration=5.28s, cumulative=5.28s)
>> starting inference...
Use the specified emotion vector
  0%|          | 0/25 [00:00<?, ?it/s]  4%|▍         | 1/25 [00:00<00:13,  1.74it/s] 12%|█▏        | 3/25 [00:00<00:04,  4.64it/s] 16%|█▌        | 4/25 [00:00<00:03,  5.61it/s] 20%|██        | 5/25 [00:00<00:03,  6.46it/s] 24%|██▍       | 6/25 [00:01<00:02,  6.91it/s] 32%|███▏      | 8/25 [00:01<00:02,  8.32it/s] 36%|███▌      | 9/25 [00:01<00:01,  8.61it/s] 44%|████▍     | 11/25 [00:01<00:01,  9.74it/s] 52%|█████▏    | 13/25 [00:01<00:01, 10.55it/s] 60%|██████    | 15/25 [00:01<00:00, 10.09it/s] 68%|██████▊   | 17/25 [00:02<00:00, 10.28it/s] 76%|███████▌  | 19/25 [00:02<00:00, 10.61it/s] 84%|████████▍ | 21/25 [00:02<00:00, 10.42it/s] 92%|█████████▏| 23/25 [00:02<00:00, 10.67it/s]100%|██████████| 25/25 [00:02<00:00, 10.49it/s]100%|██████████| 25/25 [00:02<00:00,  8.71it/s]
torch.Size([1, 85760])
>> gpt_gen_time: 17.83 seconds
>> gpt_forward_time: 0.11 seconds
>> s2mel_time: 2.89 seconds
>> bigvgan_time: 0.28 seconds
>> Total inference time: 21.22 seconds
>> Generated audio length: 3.89 seconds
>> RTF: 5.4558
>> starting inference...
Use the specified emotion vector
  0%|          | 0/25 [00:00<?, ?it/s]  8%|▊         | 2/25 [00:00<00:01, 13.16it/s] 16%|█▌        | 4/25 [00:00<00:03,  5.79it/s] 20%|██        | 5/25 [00:00<00:03,  5.13it/s] 24%|██▍       | 6/25 [00:01<00:04,  4.74it/s] 28%|██▊       | 7/25 [00:01<00:04,  4.49it/s] 32%|███▏      | 8/25 [00:01<00:03,  4.34it/s] 36%|███▌      | 9/25 [00:01<00:03,  4.21it/s] 40%|████      | 10/25 [00:02<00:03,  4.17it/s] 44%|████▍     | 11/25 [00:02<00:03,  4.11it/s] 48%|████▊     | 12/25 [00:02<00:03,  4.07it/s] 52%|█████▏    | 13/25 [00:02<00:02,  4.04it/s] 56%|█████▌    | 14/25 [00:03<00:02,  4.02it/s] 60%|██████    | 15/25 [00:03<00:02,  4.01it/s] 64%|██████▍   | 16/25 [00:03<00:02,  4.01it/s] 68%|██████▊   | 17/25 [00:03<00:02,  3.99it/s] 72%|███████▏  | 18/25 [00:04<00:01,  3.95it/s] 76%|███████▌  | 19/25 [00:04<00:01,  3.99it/s] 80%|████████  | 20/25 [00:04<00:01,  3.99it/s] 84%|████████▍ | 21/25 [00:04<00:01,  3.98it/s] 88%|████████▊ | 22/25 [00:05<00:00,  3.98it/s] 92%|█████████▏| 23/25 [00:05<00:00,  3.97it/s] 96%|█████████▌| 24/25 [00:05<00:00,  3.95it/s]100%|██████████| 25/25 [00:05<00:00,  3.95it/s]100%|██████████| 25/25 [00:05<00:00,  4.23it/s]
torch.Size([1, 145664])
>> gpt_gen_time: 23.86 seconds
>> gpt_forward_time: 0.07 seconds
>> s2mel_time: 5.93 seconds
>> bigvgan_time: 0.88 seconds
>> Total inference time: 31.07 seconds
>> Generated audio length: 6.61 seconds
>> RTF: 4.7035
[2] wrote data_stereo/case_002.wav (duration=6.61s, cumulative=11.89s)
>> starting inference...
Use the specified emotion vector
  0%|          | 0/25 [00:00<?, ?it/s]  4%|▍         | 1/25 [00:00<00:02,  9.12it/s] 12%|█▏        | 3/25 [00:00<00:02,  9.68it/s] 16%|█▌        | 4/25 [00:00<00:02,  9.07it/s] 20%|██        | 5/25 [00:00<00:02,  9.09it/s] 28%|██▊       | 7/25 [00:00<00:01, 10.55it/s] 36%|███▌      | 9/25 [00:00<00:01, 10.90it/s] 44%|████▍     | 11/25 [00:01<00:01,  9.98it/s] 52%|█████▏    | 13/25 [00:01<00:01,  9.90it/s] 60%|██████    | 15/25 [00:01<00:00, 10.15it/s] 68%|██████▊   | 17/25 [00:01<00:00, 10.53it/s] 76%|███████▌  | 19/25 [00:01<00:00, 10.69it/s] 84%|████████▍ | 21/25 [00:02<00:00, 11.35it/s] 92%|█████████▏| 23/25 [00:02<00:00, 12.57it/s]100%|██████████| 25/25 [00:02<00:00, 13.03it/s]100%|██████████| 25/25 [00:02<00:00, 11.03it/s]
torch.Size([1, 80896])
>> gpt_gen_time: 9.67 seconds
>> gpt_forward_time: 0.11 seconds
>> s2mel_time: 2.28 seconds
>> bigvgan_time: 0.34 seconds
>> Total inference time: 12.54 seconds
>> Generated audio length: 3.67 seconds
>> RTF: 3.4174
>> starting inference...
Use the specified emotion vector
  0%|          | 0/25 [00:00<?, ?it/s]  8%|▊         | 2/25 [00:00<00:01, 16.05it/s] 16%|█▌        | 4/25 [00:00<00:03,  6.59it/s] 20%|██        | 5/25 [00:00<00:03,  5.92it/s] 24%|██▍       | 6/25 [00:00<00:03,  5.52it/s] 28%|██▊       | 7/25 [00:01<00:03,  5.28it/s] 32%|███▏      | 8/25 [00:01<00:03,  5.12it/s] 36%|███▌      | 9/25 [00:01<00:03,  5.01it/s] 40%|████      | 10/25 [00:01<00:03,  4.93it/s] 44%|████▍     | 11/25 [00:02<00:02,  4.88it/s] 48%|████▊     | 12/25 [00:02<00:02,  4.83it/s] 52%|█████▏    | 13/25 [00:02<00:02,  4.80it/s] 56%|█████▌    | 14/25 [00:02<00:02,  4.78it/s] 60%|██████    | 15/25 [00:02<00:02,  4.77it/s] 64%|██████▍   | 16/25 [00:03<00:01,  4.76it/s] 68%|██████▊   | 17/25 [00:03<00:01,  4.74it/s] 72%|███████▏  | 18/25 [00:03<00:01,  4.73it/s] 76%|███████▌  | 19/25 [00:03<00:01,  4.73it/s] 80%|████████  | 20/25 [00:03<00:01,  4.72it/s] 84%|████████▍ | 21/25 [00:04<00:00,  4.72it/s] 88%|████████▊ | 22/25 [00:04<00:00,  4.71it/s] 92%|█████████▏| 23/25 [00:04<00:00,  4.71it/s] 96%|█████████▌| 24/25 [00:04<00:00,  4.71it/s]100%|██████████| 25/25 [00:04<00:00,  4.71it/s]100%|██████████| 25/25 [00:04<00:00,  5.01it/s]
torch.Size([1, 94976])
>> gpt_gen_time: 12.74 seconds
>> gpt_forward_time: 0.03 seconds
>> s2mel_time: 5.01 seconds
>> bigvgan_time: 0.59 seconds
>> Total inference time: 18.54 seconds
>> Generated audio length: 4.31 seconds
>> RTF: 4.3053
[3] wrote data_stereo/case_003.wav (duration=4.31s, cumulative=16.20s)
>> starting inference...
Use the specified emotion vector
  0%|          | 0/25 [00:00<?, ?it/s]  8%|▊         | 2/25 [00:00<00:01, 19.57it/s] 16%|█▌        | 4/25 [00:00<00:01, 14.22it/s] 24%|██▍       | 6/25 [00:00<00:01, 13.17it/s] 32%|███▏      | 8/25 [00:00<00:01, 12.69it/s] 40%|████      | 10/25 [00:00<00:01, 12.41it/s] 48%|████▊     | 12/25 [00:00<00:01, 12.30it/s] 56%|█████▌    | 14/25 [00:01<00:00, 12.22it/s] 64%|██████▍   | 16/25 [00:01<00:00, 12.15it/s] 72%|███████▏  | 18/25 [00:01<00:00, 12.11it/s] 80%|████████  | 20/25 [00:01<00:00, 12.07it/s] 88%|████████▊ | 22/25 [00:01<00:00, 12.05it/s] 96%|█████████▌| 24/25 [00:01<00:00, 12.01it/s]100%|██████████| 25/25 [00:02<00:00, 12.39it/s]
torch.Size([1, 79616])
>> gpt_gen_time: 10.58 seconds
>> gpt_forward_time: 0.04 seconds
>> s2mel_time: 2.03 seconds
>> bigvgan_time: 0.34 seconds
>> Total inference time: 13.15 seconds
>> Generated audio length: 3.61 seconds
>> RTF: 3.6413
>> starting inference...
Use the specified emotion vector
  0%|          | 0/25 [00:00<?, ?it/s]  8%|▊         | 2/25 [00:00<00:01, 17.02it/s] 16%|█▌        | 4/25 [00:00<00:04,  5.01it/s] 20%|██        | 5/25 [00:01<00:04,  4.36it/s] 24%|██▍       | 6/25 [00:01<00:04,  3.99it/s] 28%|██▊       | 7/25 [00:01<00:04,  3.77it/s] 32%|███▏      | 8/25 [00:01<00:04,  3.58it/s] 36%|███▌      | 9/25 [00:02<00:04,  3.52it/s] 40%|████      | 10/25 [00:02<00:04,  3.45it/s] 44%|████▍     | 11/25 [00:02<00:04,  3.40it/s] 48%|████▊     | 12/25 [00:03<00:03,  3.37it/s] 52%|█████▏    | 13/25 [00:03<00:03,  3.35it/s] 56%|█████▌    | 14/25 [00:03<00:03,  3.33it/s] 60%|██████    | 15/25 [00:04<00:03,  3.31it/s] 64%|██████▍   | 16/25 [00:04<00:02,  3.30it/s] 68%|██████▊   | 17/25 [00:04<00:02,  3.30it/s] 72%|███████▏  | 18/25 [00:04<00:02,  3.29it/s] 76%|███████▌  | 19/25 [00:05<00:01,  3.29it/s] 80%|████████  | 20/25 [00:05<00:01,  3.26it/s] 84%|████████▍ | 21/25 [00:05<00:01,  3.27it/s] 88%|████████▊ | 22/25 [00:06<00:00,  3.27it/s] 92%|█████████▏| 23/25 [00:06<00:00,  3.28it/s] 96%|█████████▌| 24/25 [00:06<00:00,  3.27it/s]100%|██████████| 25/25 [00:07<00:00,  3.27it/s]100%|██████████| 25/25 [00:07<00:00,  3.52it/s]
torch.Size([1, 196352])
>> gpt_gen_time: 23.55 seconds
>> gpt_forward_time: 0.03 seconds
>> s2mel_time: 7.14 seconds
>> bigvgan_time: 1.10 seconds
>> Total inference time: 32.16 seconds
>> Generated audio length: 8.90 seconds
>> RTF: 3.6118
[4] wrote data_stereo/case_004.wav (duration=8.90s, cumulative=25.10s)
>> starting inference...
Use the specified emotion vector
  0%|          | 0/25 [00:00<?, ?it/s]  8%|▊         | 2/25 [00:00<00:01, 18.92it/s] 16%|█▌        | 4/25 [00:00<00:01, 13.03it/s] 24%|██▍       | 6/25 [00:00<00:01, 12.93it/s] 32%|███▏      | 8/25 [00:00<00:01, 12.87it/s] 40%|████      | 10/25 [00:00<00:01, 12.82it/s] 48%|████▊     | 12/25 [00:00<00:01, 12.79it/s] 56%|█████▌    | 14/25 [00:01<00:00, 12.78it/s] 64%|██████▍   | 16/25 [00:01<00:00, 12.75it/s] 72%|███████▏  | 18/25 [00:01<00:00, 12.75it/s] 80%|████████  | 20/25 [00:01<00:00, 12.72it/s] 88%|████████▊ | 22/25 [00:01<00:00, 12.71it/s] 96%|█████████▌| 24/25 [00:01<00:00, 12.71it/s]100%|██████████| 25/25 [00:01<00:00, 12.87it/s]
torch.Size([1, 70400])
>> gpt_gen_time: 9.62 seconds
>> gpt_forward_time: 0.08 seconds
>> s2mel_time: 1.96 seconds
>> bigvgan_time: 0.31 seconds
>> Total inference time: 12.11 seconds
>> Generated audio length: 3.19 seconds
>> RTF: 3.7917
>> starting inference...
Use the specified emotion vector
  0%|          | 0/25 [00:00<?, ?it/s]  8%|▊         | 2/25 [00:00<00:01, 13.81it/s] 16%|█▌        | 4/25 [00:00<00:03,  5.68it/s] 20%|██        | 5/25 [00:00<00:03,  5.07it/s] 24%|██▍       | 6/25 [00:01<00:04,  4.70it/s] 28%|██▊       | 7/25 [00:01<00:04,  4.47it/s] 32%|███▏      | 8/25 [00:01<00:03,  4.32it/s] 36%|███▌      | 9/25 [00:01<00:03,  4.22it/s] 40%|████      | 10/25 [00:02<00:03,  4.15it/s] 44%|████▍     | 11/25 [00:02<00:03,  4.11it/s] 48%|████▊     | 12/25 [00:02<00:03,  4.08it/s] 52%|█████▏    | 13/25 [00:02<00:02,  4.05it/s] 56%|█████▌    | 14/25 [00:03<00:02,  4.03it/s] 60%|██████    | 15/25 [00:03<00:02,  4.02it/s] 64%|██████▍   | 16/25 [00:03<00:02,  4.01it/s] 68%|██████▊   | 17/25 [00:03<00:01,  4.01it/s] 72%|███████▏  | 18/25 [00:04<00:01,  4.00it/s] 76%|███████▌  | 19/25 [00:04<00:01,  3.99it/s] 80%|████████  | 20/25 [00:04<00:01,  3.99it/s] 84%|████████▍ | 21/25 [00:04<00:01,  3.98it/s] 88%|████████▊ | 22/25 [00:05<00:00,  3.98it/s] 92%|█████████▏| 23/25 [00:05<00:00,  3.98it/s] 96%|█████████▌| 24/25 [00:05<00:00,  3.98it/s]100%|██████████| 25/25 [00:05<00:00,  3.98it/s]100%|██████████| 25/25 [00:05<00:00,  4.24it/s]
torch.Size([1, 130560])
>> gpt_gen_time: 14.95 seconds
>> gpt_forward_time: 0.04 seconds
>> s2mel_time: 5.93 seconds
>> bigvgan_time: 0.83 seconds
>> Total inference time: 21.96 seconds
>> Generated audio length: 5.92 seconds
>> RTF: 3.7087
[5] wrote data_stereo/case_005.wav (duration=5.92s, cumulative=31.02s)
>> starting inference...
Use the specified emotion vector
  0%|          | 0/25 [00:00<?, ?it/s]  8%|▊         | 2/25 [00:00<00:01, 15.46it/s] 16%|█▌        | 4/25 [00:00<00:01, 15.62it/s] 24%|██▍       | 6/25 [00:00<00:01, 13.81it/s] 32%|███▏      | 8/25 [00:00<00:01, 13.06it/s] 40%|████      | 10/25 [00:00<00:01, 12.71it/s] 48%|████▊     | 12/25 [00:00<00:01, 12.49it/s] 56%|█████▌    | 14/25 [00:01<00:00, 12.35it/s] 64%|██████▍   | 16/25 [00:01<00:00, 12.21it/s] 72%|███████▏  | 18/25 [00:01<00:00, 11.27it/s] 80%|████████  | 20/25 [00:01<00:00, 12.06it/s] 88%|████████▊ | 22/25 [00:01<00:00, 12.36it/s] 96%|█████████▌| 24/25 [00:01<00:00, 12.24it/s]100%|██████████| 25/25 [00:02<00:00, 12.48it/s]
torch.Size([1, 75520])
>> gpt_gen_time: 8.14 seconds
>> gpt_forward_time: 0.05 seconds
>> s2mel_time: 2.01 seconds
>> bigvgan_time: 0.33 seconds
>> Total inference time: 10.66 seconds
>> Generated audio length: 3.42 seconds
>> RTF: 3.1124
>> starting inference...
Use the specified emotion vector
  0%|          | 0/25 [00:00<?, ?it/s]  8%|▊         | 2/25 [00:00<00:01, 17.59it/s] 16%|█▌        | 4/25 [00:00<00:03,  5.94it/s] 20%|██        | 5/25 [00:00<00:03,  5.22it/s] 24%|██▍       | 6/25 [00:01<00:03,  4.81it/s] 28%|██▊       | 7/25 [00:01<00:03,  4.55it/s] 32%|███▏      | 8/25 [00:01<00:03,  4.38it/s] 36%|███▌      | 9/25 [00:01<00:03,  4.27it/s] 40%|████      | 10/25 [00:02<00:03,  4.20it/s] 44%|████▍     | 11/25 [00:02<00:03,  4.14it/s] 48%|████▊     | 12/25 [00:02<00:03,  4.11it/s] 52%|█████▏    | 13/25 [00:02<00:02,  4.09it/s] 56%|█████▌    | 14/25 [00:03<00:02,  4.07it/s] 60%|██████    | 15/25 [00:03<00:02,  4.06it/s] 64%|██████▍   | 16/25 [00:03<00:02,  4.05it/s] 68%|██████▊   | 17/25 [00:03<00:01,  4.04it/s] 72%|███████▏  | 18/25 [00:04<00:01,  4.03it/s] 76%|███████▌  | 19/25 [00:04<00:01,  4.03it/s] 80%|████████  | 20/25 [00:04<00:01,  4.02it/s] 84%|████████▍ | 21/25 [00:04<00:00,  4.02it/s] 88%|████████▊ | 22/25 [00:05<00:00,  4.02it/s] 92%|█████████▏| 23/25 [00:05<00:00,  4.01it/s] 96%|█████████▌| 24/25 [00:05<00:00,  4.01it/s]100%|██████████| 25/25 [00:05<00:00,  4.01it/s]100%|██████████| 25/25 [00:05<00:00,  4.29it/s]
torch.Size([1, 121856])
>> gpt_gen_time: 14.16 seconds
>> gpt_forward_time: 0.04 seconds
>> s2mel_time: 5.84 seconds
>> bigvgan_time: 0.80 seconds
>> Total inference time: 21.04 seconds
>> Generated audio length: 5.53 seconds
>> RTF: 3.8069
[6] wrote data_stereo/case_006.wav (duration=5.53s, cumulative=36.55s)
>> starting inference...
Use the specified emotion vector
  0%|          | 0/25 [00:00<?, ?it/s]  8%|▊         | 2/25 [00:00<00:01, 19.65it/s] 16%|█▌        | 4/25 [00:00<00:01, 12.93it/s] 24%|██▍       | 6/25 [00:00<00:01, 12.44it/s] 32%|███▏      | 8/25 [00:00<00:01, 12.32it/s] 40%|████      | 10/25 [00:00<00:01, 12.18it/s] 48%|████▊     | 12/25 [00:00<00:01, 12.08it/s] 56%|█████▌    | 14/25 [00:01<00:00, 12.04it/s] 64%|██████▍   | 16/25 [00:01<00:00, 12.00it/s] 72%|███████▏  | 18/25 [00:01<00:00, 11.97it/s] 80%|████████  | 20/25 [00:01<00:00, 11.97it/s] 88%|████████▊ | 22/25 [00:01<00:00, 11.95it/s] 96%|█████████▌| 24/25 [00:01<00:00, 11.95it/s]100%|██████████| 25/25 [00:02<00:00, 12.18it/s]
torch.Size([1, 76544])
>> gpt_gen_time: 8.52 seconds
>> gpt_forward_time: 0.04 seconds
>> s2mel_time: 2.06 seconds
>> bigvgan_time: 0.33 seconds
>> Total inference time: 11.08 seconds
>> Generated audio length: 3.47 seconds
>> RTF: 3.1921
>> starting inference...
Use the specified emotion vector
  0%|          | 0/25 [00:00<?, ?it/s]  8%|▊         | 2/25 [00:00<00:01, 17.79it/s] 16%|█▌        | 4/25 [00:00<00:03,  5.85it/s] 20%|██        | 5/25 [00:00<00:03,  5.16it/s] 24%|██▍       | 6/25 [00:01<00:03,  4.75it/s] 28%|██▊       | 7/25 [00:01<00:03,  4.50it/s] 32%|███▏      | 8/25 [00:01<00:03,  4.34it/s] 36%|███▌      | 9/25 [00:01<00:03,  4.23it/s] 40%|████      | 10/25 [00:02<00:03,  4.16it/s] 44%|████▍     | 11/25 [00:02<00:03,  4.09it/s] 48%|████▊     | 12/25 [00:02<00:03,  4.04it/s] 52%|█████▏    | 13/25 [00:02<00:02,  4.01it/s] 56%|█████▌    | 14/25 [00:03<00:02,  3.99it/s] 60%|██████    | 15/25 [00:03<00:02,  3.98it/s] 64%|██████▍   | 16/25 [00:03<00:02,  3.96it/s] 68%|██████▊   | 17/25 [00:03<00:02,  3.96it/s] 72%|███████▏  | 18/25 [00:04<00:01,  3.96it/s] 76%|███████▌  | 19/25 [00:04<00:01,  3.95it/s] 80%|████████  | 20/25 [00:04<00:01,  3.94it/s] 84%|████████▍ | 21/25 [00:04<00:01,  3.93it/s] 88%|████████▊ | 22/25 [00:05<00:00,  3.95it/s] 92%|█████████▏| 23/25 [00:05<00:00,  3.95it/s] 96%|█████████▌| 24/25 [00:05<00:00,  3.96it/s]100%|██████████| 25/25 [00:05<00:00,  3.96it/s]100%|██████████| 25/25 [00:05<00:00,  4.23it/s]
torch.Size([1, 123136])
>> gpt_gen_time: 13.23 seconds
>> gpt_forward_time: 0.04 seconds
>> s2mel_time: 5.93 seconds
>> bigvgan_time: 0.81 seconds
>> Total inference time: 20.21 seconds
>> Generated audio length: 5.58 seconds
>> RTF: 3.6191
[7] wrote data_stereo/case_007.wav (duration=5.58s, cumulative=42.13s)
>> starting inference...
Use the specified emotion vector
  0%|          | 0/25 [00:00<?, ?it/s]  8%|▊         | 2/25 [00:00<00:01, 15.38it/s] 16%|█▌        | 4/25 [00:00<00:03,  6.61it/s] 20%|██        | 5/25 [00:00<00:03,  5.90it/s] 24%|██▍       | 6/25 [00:00<00:03,  5.48it/s] 28%|██▊       | 7/25 [00:01<00:03,  5.22it/s] 48%|████▊     | 12/25 [00:01<00:01, 10.09it/s] 52%|█████▏    | 13/25 [00:01<00:01,  8.47it/s] 56%|█████▌    | 14/25 [00:01<00:01,  7.34it/s] 60%|██████    | 15/25 [00:02<00:01,  6.56it/s] 64%|██████▍   | 16/25 [00:02<00:01,  5.99it/s] 68%|██████▊   | 17/25 [00:02<00:01,  5.59it/s] 72%|███████▏  | 18/25 [00:02<00:01,  5.32it/s] 76%|███████▌  | 19/25 [00:02<00:01,  5.12it/s] 80%|████████  | 20/25 [00:03<00:01,  4.98it/s] 84%|████████▍ | 21/25 [00:03<00:00,  4.89it/s] 88%|████████▊ | 22/25 [00:03<00:00,  4.82it/s] 92%|█████████▏| 23/25 [00:03<00:00,  4.77it/s] 96%|█████████▌| 24/25 [00:04<00:00,  4.73it/s]100%|██████████| 25/25 [00:04<00:00,  4.71it/s]100%|██████████| 25/25 [00:04<00:00,  5.87it/s]
torch.Size([1, 96256])
>> gpt_gen_time: 10.45 seconds
>> gpt_forward_time: 0.04 seconds
>> s2mel_time: 5.06 seconds
>> bigvgan_time: 0.60 seconds
>> Total inference time: 16.31 seconds
>> Generated audio length: 4.37 seconds
>> RTF: 3.7365
>> starting inference...
Use the specified emotion vector
  0%|          | 0/25 [00:00<?, ?it/s]  8%|▊         | 2/25 [00:00<00:01, 14.70it/s] 16%|█▌        | 4/25 [00:00<00:03,  5.72it/s] 20%|██        | 5/25 [00:00<00:03,  5.02it/s] 24%|██▍       | 6/25 [00:01<00:04,  4.65it/s] 28%|██▊       | 7/25 [00:01<00:04,  4.39it/s] 32%|███▏      | 8/25 [00:01<00:03,  4.25it/s] 36%|███▌      | 9/25 [00:01<00:03,  4.13it/s] 40%|████      | 10/25 [00:02<00:03,  4.07it/s] 44%|████▍     | 11/25 [00:02<00:03,  4.01it/s] 48%|████▊     | 12/25 [00:02<00:03,  3.97it/s] 52%|█████▏    | 13/25 [00:02<00:03,  3.95it/s] 56%|█████▌    | 14/25 [00:03<00:02,  3.93it/s] 60%|██████    | 15/25 [00:03<00:02,  3.92it/s] 64%|██████▍   | 16/25 [00:03<00:02,  3.91it/s] 68%|██████▊   | 17/25 [00:03<00:02,  3.91it/s] 72%|███████▏  | 18/25 [00:04<00:01,  3.91it/s] 76%|███████▌  | 19/25 [00:04<00:01,  3.90it/s] 80%|████████  | 20/25 [00:04<00:01,  3.89it/s] 84%|████████▍ | 21/25 [00:04<00:01,  3.90it/s] 88%|████████▊ | 22/25 [00:05<00:00,  3.89it/s] 92%|█████████▏| 23/25 [00:05<00:00,  3.89it/s] 96%|█████████▌| 24/25 [00:05<00:00,  3.89it/s]100%|██████████| 25/25 [00:06<00:00,  3.89it/s]100%|██████████| 25/25 [00:06<00:00,  4.15it/s]
torch.Size([1, 141568])
>> gpt_gen_time: 15.89 seconds
>> gpt_forward_time: 0.07 seconds
>> s2mel_time: 6.04 seconds
>> bigvgan_time: 0.87 seconds
>> Total inference time: 23.09 seconds
>> Generated audio length: 6.42 seconds
>> RTF: 3.5970
[8] wrote data_stereo/case_008.wav (duration=6.42s, cumulative=48.55s)

Done. JSONL index written to: /tmp/moshi_regress_large_legacy/moshi_parity_harness_legacy.jsonl
Summary -> samples: 8, total duration: 48.55s, avg: 6.07s
You can now run (from moshi-finetune repo):
  python annotate.py /tmp/moshi_regress_large_legacy/moshi_parity_harness_legacy.jsonl
