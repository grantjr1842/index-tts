Building server...
    Finished `release` profile [optimized] target(s) in 0.24s
Starting server with optimizations...
Initializing Python...
Loading IndexTTS2...
Model config: use_fp16=true, use_torch_compile=true, use_accel=false, use_deepspeed=true
Importing omegaconf...
Importing indextts.gpt.model_v2...
Importing transformers...
Importing GPT2Config...
Importing Cache...
Importing GenerationMixin...
Importing GPT2PreTrainedModel...
transformers_gpt2: Importing torch...
transformers_gpt2: Importing transformers.activations...
transformers_gpt2: Importing local generation utils...
transformers_gpt2: Importing local modeling utils...
transformers_modeling_utils: Importing standard libs...
transformers_modeling_utils: Importing torch...
transformers_modeling_utils: Importing GenerationMixin...
transformers_modeling_utils: Importing integrations...
transformers_modeling_utils: Importing utils...
transformers_modeling_utils: Imports done.
transformers_modeling_utils: Importing hub...
transformers_modeling_utils: Importing import_utils...
transformers_modeling_utils: Importing quantization_config...
transformers_modeling_utils: All imports done.
transformers_gpt2: Importing attn_mask_utils...
transformers_gpt2: Importing pytorch_utils...
transformers_gpt2: Imports done.
Importing Conformer/Perceiver...
Finished importing indextts.gpt.model_v2
Importing indextts.utils.maskgct_utils...
Importing indextts.utils.checkpoint...
Importing indextts.utils.front...
Importing indextts.s2mel.modules...
Importing transformers/modelscope...
Imports done.
[2025-12-07 18:28:29,219] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-12-07 18:28:31,979] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-12-07 18:28:31,990] [INFO] [logging.py:107:log_dist] [Rank -1] DeepSpeed info: version=0.17.1, git-hash=unknown, git-branch=unknown
[2025-12-07 18:28:31,991] [WARNING] [config_utils.py:70:_process_deprecated_field] Config parameter mp_size is deprecated use tensor_parallel.tp_size instead
[2025-12-07 18:28:31,992] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-12-07 18:28:31,993] [INFO] [logging.py:107:log_dist] [Rank -1] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1
[2025-12-07 18:28:32,096] [INFO] [logging.py:107:log_dist] [Rank -1] DeepSpeed-Inference config: {'layer_id': 0, 'hidden_size': 1280, 'intermediate_size': 5120, 'heads': 20, 'num_hidden_layers': -1, 'dtype': torch.float16, 'pre_layer_norm': True, 'norm_type': <NormType.LayerNorm: 1>, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-05, 'mp_size': 1, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'rotary_dim': -1, 'rotate_half': False, 'rotate_every_two': True, 'return_tuple': True, 'mlp_after_attn': True, 'mlp_act_func_type': <ActivationFuncType.GELU: 1>, 'training_mp_size': 1, 'bigscience_bloom': False, 'max_out_tokens': 1024, 'min_out_tokens': 1, 'scale_attn_by_inverse_layer_idx': False, 'enable_qkv_quantization': False, 'use_mup': False, 'return_single_tuple': False, 'set_empty_params': False, 'transposed_mode': False, 'use_triton': False, 'triton_autotune': False, 'num_kv': -1, 'rope_theta': 10000, 'invert_mask': True}

thread 'main' (273071) panicked at src/main.rs:63:37:
Failed to load TTS model: PyErr { type: <class 'RuntimeError'>, value: RuntimeError('Ninja is required to load C++ extensions (pip install ninja to get it)'), traceback: Some("Traceback (most recent call last):\n  File \"/home/admin-grant-jr/github/index-tts/indextts/infer_v2.py\", line 133, in __init__\n    self.gpt.post_init_gpt2_config(use_deepspeed=use_deepspeed, kv_cache=True, half=self.use_fp16)\n  File \"/home/admin-grant-jr/github/index-tts/indextts/gpt/model_v2.py\", line 511, in post_init_gpt2_config\n    self.ds_engine = deepspeed.init_inference(model=self.inference_model,\n  File \"/home/admin-grant-jr/github/index-tts/.venv/lib/python3.10/site-packages/deepspeed/__init__.py\", line 364, in init_inference\n    engine = InferenceEngine(model, config=ds_inference_config)\n  File \"/home/admin-grant-jr/github/index-tts/.venv/lib/python3.10/site-packages/deepspeed/inference/engine.py\", line 154, in __init__\n    self._apply_injection_policy(config)\n  File \"/home/admin-grant-jr/github/index-tts/.venv/lib/python3.10/site-packages/deepspeed/inference/engine.py\", line 388, in _apply_injection_policy\n    replace_transformer_layer(client_module, self.module, checkpoint, config, self.config)\n  File \"/home/admin-grant-jr/github/index-tts/.venv/lib/python3.10/site-packages/deepspeed/module_inject/replace_module.py\", line 400, in replace_transformer_layer\n    replaced_module = replace_module(model=model,\n  File \"/home/admin-grant-jr/github/index-tts/.venv/lib/python3.10/site-packages/deepspeed/module_inject/replace_module.py\", line 653, in replace_module\n    replaced_module, _ = _replace_module(model, policy, state_dict=sd)\n  File \"/home/admin-grant-jr/github/index-tts/.venv/lib/python3.10/site-packages/deepspeed/module_inject/replace_module.py\", line 713, in _replace_module\n    _, layer_id = _replace_module(child,\n  File \"/home/admin-grant-jr/github/index-tts/.venv/lib/python3.10/site-packages/deepspeed/module_inject/replace_module.py\", line 713, in _replace_module\n    _, layer_id = _replace_module(child,\n  File \"/home/admin-grant-jr/github/index-tts/.venv/lib/python3.10/site-packages/deepspeed/module_inject/replace_module.py\", line 689, in _replace_module\n    replaced_module = policies[child.__class__][0](child,\n  File \"/home/admin-grant-jr/github/index-tts/.venv/lib/python3.10/site-packages/deepspeed/module_inject/replace_module.py\", line 327, in replace_fn\n    new_module = replace_with_policy(child,\n  File \"/home/admin-grant-jr/github/index-tts/.venv/lib/python3.10/site-packages/deepspeed/module_inject/replace_module.py\", line 248, in replace_with_policy\n    _container.create_module()\n  File \"/home/admin-grant-jr/github/index-tts/.venv/lib/python3.10/site-packages/deepspeed/module_inject/containers/gpt2.py\", line 20, in create_module\n    self.module = DeepSpeedGPTInference(_config, mp_group=self.mp_group)\n  File \"/home/admin-grant-jr/github/index-tts/.venv/lib/python3.10/site-packages/deepspeed/model_implementations/transformers/ds_gpt.py\", line 20, in __init__\n    super().__init__(config, mp_group, quantize_scales, quantize_groups, merge_count, mlp_extra_grouping)\n  File \"/home/admin-grant-jr/github/index-tts/.venv/lib/python3.10/site-packages/deepspeed/model_implementations/transformers/ds_transformer.py\", line 68, in __init__\n    self.attention = DeepSpeedSelfAttention(self.config, mp_group, quantize_scales, quantize_groups,\n  File \"/home/admin-grant-jr/github/index-tts/.venv/lib/python3.10/site-packages/deepspeed/ops/transformer/inference/ds_attention.py\", line 79, in __init__\n    self.qkv_func = QKVGemmOp(config)\n  File \"/home/admin-grant-jr/github/index-tts/.venv/lib/python3.10/site-packages/deepspeed/ops/transformer/inference/op_binding/qkv_gemm.py\", line 18, in __init__\n    super(QKVGemmOp, self).__init__(config)\n  File \"/home/admin-grant-jr/github/index-tts/.venv/lib/python3.10/site-packages/deepspeed/ops/transformer/inference/op_binding/base.py\", line 20, in __init__\n    BaseOp.inference_module = builder.load()\n  File \"/home/admin-grant-jr/github/index-tts/.venv/lib/python3.10/site-packages/deepspeed/ops/op_builder/builder.py\", line 540, in load\n    return self.jit_load(verbose)\n  File \"/home/admin-grant-jr/github/index-tts/.venv/lib/python3.10/site-packages/deepspeed/ops/op_builder/builder.py\", line 587, in jit_load\n    op_module = load(name=self.name,\n  File \"/home/admin-grant-jr/github/index-tts/.venv/lib/python3.10/site-packages/torch/utils/cpp_extension.py\", line 1681, in load\n    return _jit_compile(\n  File \"/home/admin-grant-jr/github/index-tts/.venv/lib/python3.10/site-packages/torch/utils/cpp_extension.py\", line 2138, in _jit_compile\n    _write_ninja_file_and_build_library(\n  File \"/home/admin-grant-jr/github/index-tts/.venv/lib/python3.10/site-packages/torch/utils/cpp_extension.py\", line 2248, in _write_ninja_file_and_build_library\n    verify_ninja_availability()\n  File \"/home/admin-grant-jr/github/index-tts/.venv/lib/python3.10/site-packages/torch/utils/cpp_extension.py\", line 2309, in verify_ninja_availability\n    raise RuntimeError(\"Ninja is required to load C++ extensions (pip install ninja to get it)\")\n") }
note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace
